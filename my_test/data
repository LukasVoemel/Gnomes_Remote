{
    "policy_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVMAAAAAAAAACMHnN0YWJsZV9iYXNlbGluZXMzLnNhYy5wb2xpY2llc5SMCVNBQ1BvbGljeZSTlC4=",
        "__module__": "stable_baselines3.sac.policies",
        "__doc__": "\n    Policy class (with both actor and critic) for SAC.\n\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param lr_schedule: Learning rate schedule (could be constant)\n    :param net_arch: The specification of the policy and value networks.\n    :param activation_fn: Activation function\n    :param use_sde: Whether to use State Dependent Exploration or not\n    :param log_std_init: Initial value for the log standard deviation\n    :param sde_net_arch: Network architecture for extracting features\n        when using gSDE. If None, the latent features from the policy will be used.\n        Pass an empty list to use the states as features.\n    :param use_expln: Use ``expln()`` function instead of ``exp()`` when using gSDE to ensure\n        a positive standard deviation (cf paper). It allows to keep variance\n        above zero and prevent it from growing too fast. In practice, ``exp()`` is usually enough.\n    :param clip_mean: Clip the mean output when using gSDE to avoid numerical instability.\n    :param features_extractor_class: Features extractor to use.\n    :param features_extractor_kwargs: Keyword arguments\n        to pass to the features extractor.\n    :param normalize_images: Whether to normalize images or not,\n         dividing by 255.0 (True by default)\n    :param optimizer_class: The optimizer to use,\n        ``th.optim.Adam`` by default\n    :param optimizer_kwargs: Additional keyword arguments,\n        excluding the learning rate, to pass to the optimizer\n    :param n_critics: Number of critic networks to create.\n    :param share_features_extractor: Whether to share or not the features extractor\n        between the actor and the critic (this saves computation time)\n    ",
        "__init__": "<function SACPolicy.__init__ at 0x7fe1bf86c160>",
        "_build": "<function SACPolicy._build at 0x7fe1bf86c1f0>",
        "_get_constructor_parameters": "<function SACPolicy._get_constructor_parameters at 0x7fe1bf86c280>",
        "reset_noise": "<function SACPolicy.reset_noise at 0x7fe1bf86c310>",
        "make_actor": "<function SACPolicy.make_actor at 0x7fe1bf86c3a0>",
        "make_critic": "<function SACPolicy.make_critic at 0x7fe1bf86c430>",
        "forward": "<function SACPolicy.forward at 0x7fe1bf86c4c0>",
        "_predict": "<function SACPolicy._predict at 0x7fe1bf86c550>",
        "set_training_mode": "<function SACPolicy.set_training_mode at 0x7fe1bf86c5e0>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x7fe1bf86b640>"
    },
    "verbose": 1,
    "policy_kwargs": {
        "use_sde": false
    },
    "observation_space": {
        ":type:": "<class 'gym.spaces.box.Box'>",
        ":serialized:": "gAWV7wEAAAAAAACMDmd5bS5zcGFjZXMuYm94lIwDQm94lJOUKYGUfZQojAVkdHlwZZSMBW51bXB5lGgFk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGKMBl9zaGFwZZRLEIWUjANsb3eUjBJudW1weS5jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWQAAAAAAAAAAAAIC/AACAvwAAgL8AAIC/AACAvwAAgL8AAIC/AACAvwAAgL8AAIC/AACAvwAAgL8AAIC/AACAvwAAgL8AAIC/lGgKSxCFlIwBQ5R0lFKUjARoaWdolGgSKJZAAAAAAAAAAAAAgD8AAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/AACAPwAAgD8AAIA/AACAPwAAgD+UaApLEIWUaBV0lFKUjA1ib3VuZGVkX2JlbG93lGgSKJYQAAAAAAAAAAEBAQEBAQEBAQEBAQEBAQGUaAeMAmIxlImIh5RSlChLA4wBfJROTk5K/////0r/////SwB0lGJLEIWUaBV0lFKUjA1ib3VuZGVkX2Fib3ZllGgSKJYQAAAAAAAAAAEBAQEBAQEBAQEBAQEBAQGUaCFLEIWUaBV0lFKUjApfbnBfcmFuZG9tlE51Yi4=",
        "dtype": "float32",
        "_shape": [
            16
        ],
        "low": "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]",
        "high": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]",
        "bounded_below": "[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True]",
        "bounded_above": "[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True]",
        "_np_random": null
    },
    "action_space": {
        ":type:": "<class 'gym.spaces.box.Box'>",
        ":serialized:": "gAWV9QsAAAAAAACMDmd5bS5zcGFjZXMuYm94lIwDQm94lJOUKYGUfZQojAVkdHlwZZSMBW51bXB5lGgFk5SMAmY0lImIh5RSlChLA4wBPJROTk5K/////0r/////SwB0lGKMBl9zaGFwZZRLA4WUjANsb3eUjBJudW1weS5jb3JlLm51bWVyaWOUjAtfZnJvbWJ1ZmZlcpSTlCiWDAAAAAAAAAAAAIC/AACAvwAAgL+UaApLA4WUjAFDlHSUUpSMBGhpZ2iUaBIolgwAAAAAAAAAAACAPwAAgD8AAIA/lGgKSwOFlGgVdJRSlIwNYm91bmRlZF9iZWxvd5RoEiiWAwAAAAAAAAABAQGUaAeMAmIxlImIh5RSlChLA4wBfJROTk5K/////0r/////SwB0lGJLA4WUaBV0lFKUjA1ib3VuZGVkX2Fib3ZllGgSKJYDAAAAAAAAAAEBAZRoIUsDhZRoFXSUUpSMCl9ucF9yYW5kb22UjBRudW1weS5yYW5kb20uX3BpY2tsZZSMEl9fcmFuZG9tc3RhdGVfY3RvcpSTlIwHTVQxOTkzN5SFlFKUfZQojA1iaXRfZ2VuZXJhdG9ylGgwjAVzdGF0ZZR9lCiMA2tleZRoEiiWwAkAAAAAAAAiWWf/G6ESxX+xvW7ITP1SQMU/KpPsn77sn4d+nFHkn04La0LrfRsaR+mUa7WdhrIP5rcHaP8o3OGLSZFnGXWW88cKSrMJdiEqgSdfDhx1x4elViM6yxxSMe8Lg+/v9+TaXeLT5ys/YHsDt/6PyeLNK3gXyI1U3V3qTl3WpNPzcIm4/zal+o8sxhYh0Wc4BEVLZevLF23StKfJMhv1xASdvE/GCmM2uujGvSDJOxn4jye6iuYeylFWgVPc3tXWg+zrrjKhD2An925JWseDcjyVeazA3hMz0bu7Yi6IMWONwh5UgUrGkl1Y4gEbyMBILrpkH4XPy2ao58niV+orxZjJ3Mt2MfIDrArF+QS/gAKTU1f+OG9wY6V6GgIdvGHwrQKWW8XOTUtrg45hd1aiJdKkRSXVblPWJv7jPZzcm3wvByr8h5j4uqVX8oYOprxjPgwrJvnUuavZRmsJ2krSziuJqrz0PEFQa9Oip8BULKT8W7gbgoPC72JRhpton789tttnLTtrHvVrpO3nJLR2FkKIDo2WX/idF42UlHjIg2ZpDplTJFtmh6bUAboT1s4hqKP5uCZpZcJOiJwTN66uSkjav0nQaLyKsYnuUYXYyI3Y6dzLr49kWp1ivBaU70CTDzpg/T1eIQvL1J4KBLx1Tm6/Kv2G50uYN5HRtbRgWlXHiaVZq+kXVmO8bD3AUknDKIdMXRORhUv/IvM0emBCGsat/LlGYnAVpORnMR0c21xlL/De8EpCYIMJnN3GuuSm6AY678du2RXN/ebftSdPHuNfbA8GsxSsWQLKRNQQCpM3wM2iwDhibUtwYcSZnmvIFwoSK9S5aqmpi8hx+/1T7/Qc3njzZNpyF52HkCWZ2BrRy/QXTa2mMwGd2e6LQjEQ4CVuz/79nKDK7CNNzyleJF+/eiiwuDzTkRYXXBkOlGJzyeNqQoCqhUvPqbyoo4xkdOyIo4hPn4Vs3FQ78RkkrHZTH4Gb3SZgDrKqF2gW9rtCNuuKXmAQmgZIppZmuJOoRMgii/XQJjcmYGloMFniv4ogenXJTgc+KJhL+sxhdgL6daiL8jHD3hrSORfQAKXlGhu6fWlgwlyMUWAOHTxumNjuj2nEPkggM24isp2GM8SjXVByf0YSTb6cjw9a8/HJs5jJnIUUkR9fz14ahQzrvXq/+Olv0v4r4szOdtuG8d2LC3dzqGs7inJqR2HZFKcZmQ0qzw8q2y6iQJrLfMKYZAh7ruuavqC4BmMhQ4waUzZkHPda/+JepAByq0Rjov5bIOlLMd49RbmR5pU2gS7IlbeUNJwZv2YekboGwxQ3X3wnsS9LuiEMnvEzPfLmghN+J4BX423eNk/EPuNhChRD8/dKFYcyAzsY1HSEE+K613fkFk782qnM5SpxHNQ8PuFWzdscAfL/f081blfvEvMicQMuqbMJ+RErsXEfST/WL3VligOhXxxsdxSediRB2E9i0TShp4gx0PkUUkcfgl7tUCkIN0pT/nyiJ7kxuXUD+zyKzQ6XiCCgqYrS2DJNK7nwd+uybYMxoE7UH1o9Z2F8U2LqVo+PdoFZhjIrEO80K7ExuU3IiKb2676ExeubBFwvzd7rWVb+WmiGbZX2Cy5IpIGlFzCDtupGhRZ6iEgX0aPByld1YunEhWR0tZj2nnbi4h/Mqgads1Z3JIhjOv9CP8PyTSX7RnxBvj+D/i5F6YSMYAPNUWdxfye3FAhFOdc+VcDjEtZY8qihGCQv3b1IJTZM8A9glQUl3NYLlhITPHcz0hrJzW1t9YSbcV4jQmIcTHkFfP+MnaYGd5zu3mTctYzGvhP2LzzKUOkby3Dk/vnTjsxfpdd8NdnVjdFwxidaE8II+9rPjBj2x+5DFQr5SgRaVnGc/du5hCucyU9dferFNYWzrZD7nweBS5tMKX9mEaG0Qd/CIJBV8yg4lEAueBjiyLfSUgL8iNugelyYPl4XeGi/qVGndIjx+2vDQjttmHlq/uVWrbWPA2QCIgIqS2Ve2B8a1X3NdO2UJeA8cGc1yyM2FYA9JK7Jno0+i8TWrbYz1ZmX0slgPe/eY1CgPtmoM2tqkA9OFbXn+s7mZxKX6re9kPX0NVhr04KE3XdNu6d8Nqmg6AVMOQ8ZxkX58FySYoVuKRFs7yPWBdGMeHxMr8xQgwVYJTSdj/hyhA1Yi8Waw9tYpq06Gph0xEoEUHW1srA1TZL3/ZB3tpIUxda1dU5n+oDzkmNsHffOXYhYpyYbwXKQSLWbctOoLR1gaoet135UIM1lXba+woMnzn/0oaDbbk9P+nREqGsst9I3dlmUq5Nk6JOYSoWHWe91KTJdftNSyAiky+oKwU5p87Q5C1wVcHst3qNtHN0swv9rvz51ayKrFKl8RCyeTDhZieiylAR9vQaaRVDkahTPhM/wf0FABa63tof/NIiWZ+WYieB6tnlP85fGni9QLa+4+GevodhpwIya3XrQFA2Jog5W66wCtZN92NGgfjLk25/6XJ/7xsIGbkufPJv3A1nH/VLePldq8mdnmFyQ6B808cbGXrRSCKoLen0Ac1iFBx+V/Us1qonLIKZck6I36DlJzti4UJBck+IfhOLoi6XbWC53Qms/C7lRwc9TKT4O5kSK4zmrANr67kTbVsnA0eZrlPuVTEIKz0m5pXjA75gwrxzu5MCxW4e1PuaGJEHc7LR2tU6+vdjhIXL3yVLTtSmUthwaSEDx4lw/nCPMQYG7Y+n0biYDQDVM5ZLN05x1cp2kHRloNwMc3vNSeZRR9gy61R725jNW8AGox4qpiHJhVHevrTajEB41kOhbFFaMnsTyIOOUgKYR7R+CBRzsiTT9tCdeV4U+2EIsNdSTFWE+b65bwvUbySlzbYpKuF6uLeSLhmH5Zui3vLk0Bxjyix0KvZbvXKrS/r3+fBglzm+eIHHMW+2SaffHyxXagXTUovTRs5T+80n1DW+wuRoBaELYqps4e153u2sNWmBl1/VoHX8JeTWt2BxSVYz50FEX++S/+B17WRdwfEUyXxPNtMxqwLjbYtTM3sF+lbP1YbPARazZfVsRJ8ozvuMuU76AlylTKxldHejipxs4P57BZBatbemdEX9yDxd9pM1MeHcz2Ys2vI8X3WykH1CdAdVDH8qZ6Rg6nA5XrRCgOvmncEnRFzzTX2I2juTT8ftrC7B/x4+pfUZeDRpVtn//I0ZeKQfuCcMvG9VOhM8Knb7UqDBGZN2HSqG27WTpK+cx/v9aepLWcdvxuXWOU4KkYEqftYJgoo1JpWJwyJiM/V0EgVq0nDJBobpyfiHykQtNvyWco5XXEfvZPllqAhdwy3LAZ+2aGp+UaAeMAnU0lImIh5RSlChLA2gLTk5OSv////9K/////0sAdJRiTXAChZRoFXSUUpSMA3Bvc5RNLAF1jAloYXNfZ2F1c3OUSwCMBWdhdXNzlEcAAAAAAAAAAHVidWIu",
        "dtype": "float32",
        "_shape": [
            3
        ],
        "low": "[-1. -1. -1.]",
        "high": "[1. 1. 1.]",
        "bounded_below": "[ True  True  True]",
        "bounded_above": "[ True  True  True]",
        "_np_random": "RandomState(MT19937)"
    },
    "n_envs": 1,
    "num_timesteps": 50,
    "_total_timesteps": 50,
    "_num_timesteps_at_start": 0,
    "seed": null,
    "action_noise": null,
    "start_time": 1669432128501351000,
    "learning_rate": 0.0003,
    "tensorboard_log": null,
    "lr_schedule": {
        ":type:": "<class 'function'>",
        ":serialized:": "gAWV4QIAAAAAAACMF2Nsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX21ha2VfZnVuY3Rpb26Uk5QoaACMDV9idWlsdGluX3R5cGWUk5SMCENvZGVUeXBllIWUUpQoSwFLAEsASwFLAUsTQwSIAFMAlE6FlCmMAV+UhZSMVy9vcHQvYW5hY29uZGEzL2VudnMvZHJhZ2cvbGliL3B5dGhvbjMuOS9zaXRlLXBhY2thZ2VzL3N0YWJsZV9iYXNlbGluZXMzL2NvbW1vbi91dGlscy5weZSMBGZ1bmOUS4BDAgABlIwDdmFslIWUKXSUUpR9lCiMC19fcGFja2FnZV9flIwYc3RhYmxlX2Jhc2VsaW5lczMuY29tbW9ulIwIX19uYW1lX1+UjB5zdGFibGVfYmFzZWxpbmVzMy5jb21tb24udXRpbHOUjAhfX2ZpbGVfX5SMVy9vcHQvYW5hY29uZGEzL2VudnMvZHJhZ2cvbGliL3B5dGhvbjMuOS9zaXRlLXBhY2thZ2VzL3N0YWJsZV9iYXNlbGluZXMzL2NvbW1vbi91dGlscy5weZR1Tk5oAIwQX21ha2VfZW1wdHlfY2VsbJSTlClSlIWUdJRSlIwcY2xvdWRwaWNrbGUuY2xvdWRwaWNrbGVfZmFzdJSMEl9mdW5jdGlvbl9zZXRzdGF0ZZSTlGgffZR9lChoFmgNjAxfX3F1YWxuYW1lX1+UjBljb25zdGFudF9mbi48bG9jYWxzPi5mdW5jlIwPX19hbm5vdGF0aW9uc19flH2UjA5fX2t3ZGVmYXVsdHNfX5ROjAxfX2RlZmF1bHRzX1+UTowKX19tb2R1bGVfX5RoF4wHX19kb2NfX5ROjAtfX2Nsb3N1cmVfX5RoAIwKX21ha2VfY2VsbJSTlEc/M6kqMFUyYYWUUpSFlIwXX2Nsb3VkcGlja2xlX3N1Ym1vZHVsZXOUXZSMC19fZ2xvYmFsc19flH2UdYaUhlIwLg=="
    },
    "_last_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVtQAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJZAAAAAAAAAAAAAgL+Zhi1BAAAAAMgsXL8AAIC/AACAvwAAgL9u2k6/AACAPwAAgL9WoxlBMzOzvjMzM7/NzAy/xR00QgAAgL+UjAVudW1weZSMBWR0eXBllJOUjAJmNJSJiIeUUpQoSwOMATyUTk5OSv////9K/////0sAdJRiSwFLEIaUjAFDlHSUUpQu"
    },
    "_last_episode_starts": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVdAAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJYBAAAAAAAAAAGUjAVudW1weZSMBWR0eXBllJOUjAJiMZSJiIeUUpQoSwOMAXyUTk5OSv////9K/////0sAdJRiSwGFlIwBQ5R0lFKULg=="
    },
    "_last_original_obs": {
        ":type:": "<class 'numpy.ndarray'>",
        ":serialized:": "gAWVtQAAAAAAAACMEm51bXB5LmNvcmUubnVtZXJpY5SMC19mcm9tYnVmZmVylJOUKJZAAAAAAAAAAAAAgL9Nw1ZBAAAAAOEYbL8AAIC/AACAvwAAgL+HX8i+AACAPwAAgL+jpBRBzczMvjMzM78AAAC/RSA0QuQ4Vr+UjAVudW1weZSMBWR0eXBllJOUjAJmNJSJiIeUUpQoSwOMATyUTk5OSv////9K/////0sAdJRiSwFLEIaUjAFDlHSUUpQu"
    },
    "_episode_num": 0,
    "use_sde": false,
    "sde_sample_freq": -1,
    "_current_progress_remaining": 0.0,
    "ep_info_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVIAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKULg=="
    },
    "ep_success_buffer": {
        ":type:": "<class 'collections.deque'>",
        ":serialized:": "gAWVIAAAAAAAAACMC2NvbGxlY3Rpb25zlIwFZGVxdWWUk5QpS2SGlFKULg=="
    },
    "_n_updates": 0,
    "buffer_size": 1000000,
    "batch_size": 256,
    "learning_starts": 100,
    "tau": 0.005,
    "gamma": 0.99,
    "gradient_steps": 1,
    "optimize_memory_usage": false,
    "replay_buffer_class": {
        ":type:": "<class 'abc.ABCMeta'>",
        ":serialized:": "gAWVNQAAAAAAAACMIHN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi5idWZmZXJzlIwMUmVwbGF5QnVmZmVylJOULg==",
        "__module__": "stable_baselines3.common.buffers",
        "__doc__": "\n    Replay buffer used in off-policy algorithms like SAC/TD3.\n\n    :param buffer_size: Max number of element in the buffer\n    :param observation_space: Observation space\n    :param action_space: Action space\n    :param device: PyTorch device\n    :param n_envs: Number of parallel environments\n    :param optimize_memory_usage: Enable a memory efficient variant\n        of the replay buffer which reduces by almost a factor two the memory used,\n        at a cost of more complexity.\n        See https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195\n        and https://github.com/DLR-RM/stable-baselines3/pull/28#issuecomment-637559274\n        Cannot be used in combination with handle_timeout_termination.\n    :param handle_timeout_termination: Handle timeout termination (due to timelimit)\n        separately and treat the task as infinite horizon task.\n        https://github.com/DLR-RM/stable-baselines3/issues/284\n    ",
        "__init__": "<function ReplayBuffer.__init__ at 0x7fe1bf83c3a0>",
        "add": "<function ReplayBuffer.add at 0x7fe1bf83c430>",
        "sample": "<function ReplayBuffer.sample at 0x7fe1bf83c4c0>",
        "_get_samples": "<function ReplayBuffer._get_samples at 0x7fe1bf83c550>",
        "__abstractmethods__": "frozenset()",
        "_abc_impl": "<_abc._abc_data object at 0x7fe1bf6c98c0>"
    },
    "replay_buffer_kwargs": {},
    "train_freq": {
        ":type:": "<class 'stable_baselines3.common.type_aliases.TrainFreq'>",
        ":serialized:": "gAWVYQAAAAAAAACMJXN0YWJsZV9iYXNlbGluZXMzLmNvbW1vbi50eXBlX2FsaWFzZXOUjAlUcmFpbkZyZXGUk5RLAWgAjBJUcmFpbkZyZXF1ZW5jeVVuaXSUk5SMBHN0ZXCUhZRSlIaUgZQu"
    },
    "use_sde_at_warmup": false,
    "target_entropy": {
        ":type:": "<class 'numpy.float32'>",
        ":serialized:": "gAWVZQAAAAAAAACMFW51bXB5LmNvcmUubXVsdGlhcnJheZSMBnNjYWxhcpSTlIwFbnVtcHmUjAVkdHlwZZSTlIwCZjSUiYiHlFKUKEsDjAE8lE5OTkr/////Sv////9LAHSUYkMEAABAwJSGlFKULg=="
    },
    "ent_coef": "auto",
    "target_update_interval": 1,
    "batch_norm_stats": [],
    "batch_norm_stats_target": []
}